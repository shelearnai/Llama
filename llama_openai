{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex Bottoms-Up Development - LLMs and Prompts\n",
    "This notebook walks through testing an LLM using the primary prompt templates used in llama-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this section, we load a test document, create an LLM, and copy prompts from llama-index to test with."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load a quick document to test with. Right now, we will just load it as plain text, but we can do other operations later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create our LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex uses some simple templates under the hood for answering queries -- mainly a `text_qa_template` for obtaining initial answers, and a `refine_template` for refining an existing answer when all the text does not fit into one LLM call.\n",
    "\n",
    "Let's copy the default templates, and test out our LLM with a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "refine_template = (\n",
    "    \"We have the opportunity to refine the original answer \"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better \"\n",
    "    \"answer the question: {query_str}. \"\n",
    "    \"If the context isn't useful, output the original answer again.\\n\"\n",
    "    \"Original Answer: {existing_answer}\"\n",
    ")\n",
    "\n",
    "text_qa_template = PromptTemplate(text_qa_template)\n",
    "refine_template = PromptTemplate(refine_template)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets test a few questions!\n",
    "\n",
    "## Text QA Template Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerabilities in Large Language Models (LLMs) can be categorized into two main groups: AI Model Inherent Vulnerabilities and Non-AI Model Inherent Vulnerabilities. AI Model Inherent Vulnerabilities include issues like data poisoning, backdoor attacks, and training data extraction, while Non-AI Model Inherent Vulnerabilities encompass concerns like remote code execution, prompt injection, and side channels. These vulnerabilities pose threats to both security (e.g., remote code execution attacks) and privacy (e.g., data extraction).\n",
      "\n",
      "To defend against these vulnerabilities, strategies can be implemented at various stages. During the training phase, defenses may involve cleaning training corpora and optimizing methods. In the inference phase, defenses can include pre-processing instructions, detecting malicious behavior, and post-processing generated outputs. These defense mechanisms aim to enhance the security, robustness, and ethical alignment of LLMs.\n",
      "\n",
      "It is noted that certain types of attacks, such as model extraction and parameter extraction, have received limited research attention and remain primarily theoretical with minimal practical exploration. The large scale of LLM parameters makes traditional approaches less effective, and the confidentiality of powerful LLMs further shields them from conventional attacks. Research on the impact of model architecture on LLM safety is scarce due to high computational costs, and recent developments like safe instruction tuning require further investigation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Explain me about Vulnerabilities and defenses in LLMs.\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity refers to the accuracy, consistency, and reliability of data throughout its lifecycle. It ensures that data remains unchanged and is not altered or corrupted in any unauthorized or unintended way. This includes maintaining the completeness and reliability of data, as well as protecting it from unauthorized access, modification, or deletion. In the context of the provided text, data integrity is one of the aspects of data security and privacy that Large Language Models (LLMs) can help ensure by applying techniques such as data confidentiality protection and data traceability.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is data integrity?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index? Write your answer using only code.\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response_gen = llm.stream_complete(prompt)\n",
    "for response in response_gen:\n",
    "    print(response.delta, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine Template Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, follow these steps:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "# Load the documents from the 'data' folder\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "\n",
      "# Build the index\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "\n",
      "# Persist the index to disk\n",
      "index.storage_context.persist()\n",
      "\n",
      "# Reload the index from disk\n",
      "from llama_index import StorageContext, load_index_from_storage\n",
      "\n",
      "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
      "index = load_index_from_storage(storage_context)\n",
      "```\n",
      "\n",
      "Make sure you have installed LlamaIndex and have the necessary dependencies.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index? Write your answer using only code.\"\n",
    "existing_answer = \"\"\"To create an index using LlamaIndex, you need to follow these steps:\n",
    "\n",
    "1. Download the LlamaIndex repository by cloning it from GitHub.\n",
    "2. Navigate to the `examples/paul_graham_essay` folder in the cloned repository.\n",
    "3. Create a new Python file and import the necessary modules: `VectorStoreIndex` and `SimpleDirectoryReader`.\n",
    "4. Load the documents from the `data` folder using `SimpleDirectoryReader('data').load_data()`.\n",
    "5. Build the index using `VectorStoreIndex.from_documents(documents)`.\n",
    "6. To persist the index to disk, use `index.storage_context.persist()`.\n",
    "7. To reload the index from disk, use the `StorageContext` and `load_index_from_storage` functions.\n",
    "\n",
    "Note: This answer assumes that you have already installed LlamaIndex and have the necessary dependencies.\"\"\"\n",
    "prompt = refine_template.format(context_msg=text, query_str=question, existing_answer=existing_answer)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Example\n",
    "The LLM also has a `chat` method that takes in a list of messages, to simulate a chat session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: To create an index, you typically need to follow these steps:\n",
      "\n",
      "1. Determine the purpose of the index: Decide what you want the index to represent or measure.\n",
      "\n",
      "2. Select the components: Choose the assets, securities, or items that will be included in the index.\n",
      "\n",
      "3. Assign weights: Decide on the weighting methodology for the components of the index (e.g., market capitalization-weighted, equal-weighted, price-weighted).\n",
      "\n",
      "4. Calculate the index value: Calculate the index value based on the components and their weights.\n",
      "\n",
      "5. Rebalance the index: Regularly review and adjust the components and weights of the index to ensure it remains relevant and representative.\n",
      "\n",
      "6. Publish the index: Make the index available to users through various channels such as financial websites, data providers, or index providers.\n",
      "\n",
      "If you are specifically interested in llama-index, you can refer to the documentation or guidelines provided by llama-index to create an index using their platform.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful QA chatbot that can answer questions about llama-index.\"),\n",
    "    ChatMessage(role=\"user\", content=\"How do I create an index?\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(chat_history)\n",
    "print(response.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
