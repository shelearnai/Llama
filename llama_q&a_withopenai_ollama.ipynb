{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Prompt the user to enter their OpenAI API key securely\n",
    "OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "# Set the environment variable for the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLMs demonstrate a deep understanding of natural language text to extract relevant data for various tasks like translation or summarization. They also possess capabilities in generating human-like text when prompted with specific cues and exhibit contextual awareness by considering factors such as domain expertise, which enhances their effectiveness across diverse industries ranging from healthcare to education. Furthermore, LLMs excel at problem solving and decision making using the information found within passages in tasks like information retrieval or question answering systems.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What does LLm work on language process?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "# Local settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[SentenceSplitter(chunk_size=512)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-chroma\n",
      "  Downloading llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl.metadata (705 bytes)\n",
      "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-vector-stores-chroma) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-vector-stores-chroma) (0.10.43)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.6.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.110.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.25.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.18.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.10.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.27.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.10.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.33.0)\n",
      "Requirement already satisfied: pandas in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (10.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.37.2)\n",
      "Requirement already satisfied: anyio in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.7.1)\n",
      "Requirement already satisfied: certifi in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: click in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.5.15)\n",
      "Requirement already satisfied: coloredlogs in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.9.0)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (68.2.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (11.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.9)\n",
      "Requirement already satisfied: filelock in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.13.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.19.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/test/anaconda3/envs/gvenv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.0)\n",
      "Downloading llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: llama-index-vector-stores-chroma\n",
      "Successfully installed llama-index-vector-stores-chroma-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "chroma_client = chromadb.PersistentClient()\n",
    "chroma_collection = chroma_client.create_collection(\"llama_store_v1\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In this document's examination of language models related to security and privacy concerns, Large Language Models (LLM) are discussed as a significant advancement in the field of computational linguistics with substantial implications for various applications including cybersecurity-related tasks. An LLM is characterized by its extensive training on vast text corpora using advanced pre-training techniques which have contributed to notable progresses, particularly evident within Natural Language Processing (NLP) domains and beyond into areas like programming support vulnerability detection as well as medical text analysis among others where they play a multifaceted role.\n",
      "\n",
      "Pronunciation: \n",
      "The acronym \"LLM\" stands for Large Language Models, which are typically pronounced [lɪm]. However, in the context of technology and computing terminology like this one's document on LLM impact studies concerning security-related areas, it is often just spoken as its abbreviation without a specific additional way to be enunciated.\n",
      "\n",
      "Pros: \n",
      "One major advantage highlighted by researchers within cybersecurity applications pertaining to code safety and data protection includes the superior performance of language models when compared with traditional methods in tasks such as secure coding, test case generation or vulnerability detection throughout a software's lifecycle based on natural text comprehension. Their contribution extends beyond these areas into ensuring aspects like integrity, confidentiality, reliability, and traceability for sensitive data handling within security protocols which are crucial to safeguard digital assets against potential breaches or leaks in the cybersecurity arena where language models can provide significant support by understanding contextual information.\n",
      "\n",
      "Cons: \n",
      "On a contrasting note though LLM is acknowledged as beneficial for securing various aspects, there have been discussions regarding their susceptibility to certain threats and vulnerabilities that could compromise security integrity due in part to human-like reasoning capabilities they possess which might be exploited. These concerns are amplified by the fact that while LLMs excel at tasks requiring comprehension of extensive text passages, enhancing decision making or information retrieval systems through natural language interaction with humans and machines alike, their offensive applications in cybersecurity domains pose potential risks including hardware-level side channel attacks to software misinformation campaigns. Additionally, the document underscores a need for further research into areas like model extraction vulnerabilities as well as safe instruction tuning given current limitations related to these aspects within LLM technologies and their defenses against such threats remain in development stages or theoretical frameworks that require more empirical evidence and practical implementations respectively.\n",
      "\n",
      "To encapsulate, the document discusses language models—primarily Large Language Models (LLM) with a focus on how they are leveraged within cybersecurity realms to bolster security measures while also acknowledging potential risks associated their offensive applications alongside inherent vulnerabilities that need addressing and countermeasures development. It's an exploration of the duality in LLM utilities for both strengthening defenses as well as understanding points where they could be weakened or exploited within cybersecurity contexts, thereby presenting a comprehensive overview from various research angles to understand their full spectrum impact on security and privacy.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "response = query_engine.query(\"What does LLM mean? Explain me widely and also its prons and cons.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Local LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x7f7aea449850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global settings\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "Settings.llm = Ollama(model=\"phi3:mini\", request_timeout=60.0)\n",
    "\n",
    "# Local settings\n",
    "index.as_query_engine(llm=Ollama(model=\"phi3:mini\", request_timeout=60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedding refers to a technique that enables converting text into numerical representations, often called embedds or vectors, which can capture semantic meanings of words and phrases within language models such as LLMs. These numeric vector encodings are then used for various natural language processing tasks by large language models (LLMs).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")\n",
    "response = query_engine.query(\"What is emebdding in LLM?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Large Language Model (LLM) is a type of artificial intelligence that understands natural language by analyzing vast amounts of text data through pretraining tasks like masked language modeling and autoregressive prediction, thereby gaining comprehension about the contextualized semantics in human languages.\n",
      "\n",
      "Pronunciation: Large Language Model (LLM)\n",
      "\n",
      "Pros/Advantages - \n",
      "1. LLM has an extensive understanding of natural language due to its pretraining on large text data sets and tasks, which aids it greatly at comprehending contextualized semantics in human languages. It also exhibits the ability to generate high-quality, almost human-like text outputs after being fine-tuned further for specific purposes or domains - this is often referred as 'text generation' capability of LLMs\n",
      "2. The capacity of these models extends into knowledge-intensive areas where they can maintain a contextual awareness and understanding similar to the depth humans possess on various topics, thereby making them useful in diverse applications that require such comprehension - this is often termed as 'domain adaptation' capability \n",
      "3. LLMs also demonstrate strong abilities at following instructions which are beneficial for problem-solving or decision-making tasks where these models can assist humans by providing insightful information and suggestions based on the given instruction, thereby demonstrating their ability in this respect - often termed as 'instruction tuning' capability \n",
      "4. LLMs have shown to outperform traditional methods especially when it comes to enhancing code security through vulnerability detection or safeguarding data privacy via confidentiality protection tasks after being fine-tuned for these specific purposes - this highlights their potential in bolstering cybersecurity \n",
      "5. LLM, due to its impressive text generation and comprehension abilities along with strong instruction following skills can be an asset when it comes to creating or improving educational content thereby serving as a valuable resource at the intersection of technology and education - this is often referred as 'educational aid' capability \n",
      "6. With their profound understanding, contextual awareness especially in knowledge-intensive domains along with strong instruction following abilities LLMs can also be an asset when it comes to assisting professionals like doctors or lawyers where these models can provide supplementary insights and suggestions based on the given scenario thereby demonstrating their 'professional aid' capability \n",
      "7. Being able to generate human-like text, understanding contextual semantics in natural languages along with strong instruction following abilities LLMs also have great potential when it comes to enhancing user experience across various platforms like social media or customer support services where these models can provide personalized and engaging responses thereby demonstrating their 'user experience aid' capability \n",
      "8. When used appropriately, they could even enhance creativity in fields such as writing novels or poetry by providing inputs that mimic human-like expressions - this is often referred to as 'creative input' from LLMs  \n",
      "9. They also show potential when it comes to assisting individuals with language impairments like dyslexia, autism etc., where these models can be tailored for educational support or communication thereby demonstrating their 'supportive learning and interaction aids’ capability \n",
      "1incon: LLMs could exhibit vulnerabilities as they may inadvertently generate harmful misinformation content which might pose ethical concerns - this is often termed the 'content safety' concern of LLMs. In addition, their human-like reasoning abilities and large parameter scale can also make them susceptible to various forms of attacks wherein these models are manipulated for malicious purposes or exploited through model extraction techniques thereby demonstrating potential risks - this is often referred as 'security vulnerability' concern with LLMs. Furthermore, the limited research on safe instruction tuning and parameter-extraction attack poses an area requiring more attention in order to fully comprehend these aspects of their usage safely thus highlighting a need for further exploration \n",
      "1incon: While they exhibit strong ability at following instructions which is beneficial when it comes to problem solving or decision making, the same capability can also be exploited through user-level attacks where attackers manipulate LLMs by feeding misleading information thereby manipulating them into generating harmful outcomes - this concerns 'user-input vulnerabilities' of LLM. \n",
      "1incon: Lastly while they have shown great potential in various areas, there is still a need to understand and address their limitations like limited understanding towards offensive applications or lacking knowledge about specific domains which could affect the quality & reliability of information generated thereby highlighting an area for further research - this concerns 'domain-specific application' limitation with LLMs."
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine(streaming=True)  #streaming the response back\n",
    "response = query_engine.query(\"What does LLM mean? Explain me widely and also its prons and cons.\")\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHATBOT instead of Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To learn what the author did growing up, it would be best to look into their personal writings like memoirs or autobiographies if available, read biographical studies written by scholars in literary fields, explore interviews where they might share details of their past experiences with fans and interviewers. Online resources such as dedicated fan pages for the author's works can also provide insights into personal histories that are relevant to understanding an artist or writer better.\n",
      "\n",
      "If you have a specific name in mind, I could try using 'query_engine_tool' by inputting natural language questions about their biography and childhood experiences if such data is available within my knowledge base prior to the cutoff date of 2023-10. However, for detailed information not covered before that time or personal anecdotes shared afterward in interviews or social media posts up until now (beyond October 2023), I would suggest searching through credible biographies and reliable literary sources to find the answer you're looking for.\n",
      " To expand on this topic further, one could access various forms of literature that detail an author’s life history including but not limited to memoirs, autobiographical essays, interviews, and biographies penned by reputable authors or scholars in the field of literary studies. These narratives often provide a rich tapestry of personal experiences that shape their artistic voices.\n",
      "\n",
      "If available within my pre-October 2023 knowledge base, I could use 'query_engine_tool' with inputs like \"What were [Author Name]’s hobbies during childhood?\" or \"[Author Name] early life activities.\" However, for upcoming biographical information beyond October 2023 that isn't within my database yet and assuming it hasn't been published online in accessible formats prior to the cutoff date of this knowledge base, I would recommend reaching out directly to literary scholars who specialize in [Author Name] or their work. Alternatively, one could explore fan-curated content like essays, blogs, or articles that speculate on these aspects based on available public records and published works up until October 2023.\n",
      "\n",
      "If the author has been active online postcutoff date (such as writing a memoir article series or sharing personal stories), one might find such material in dedicated fan-sites where they compile summaries of interviews, articles by journalists specializing in contemporary authors' lives and careers, or direct quotes from social media platforms if the author shares them there.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_chat_engine()\n",
    "response = query_engine.chat(\"What did the author do growing up?\")\n",
    "print(response)\n",
    "\n",
    "response = query_engine.chat(\"Oh interesting, tell me more.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gkernel",
   "language": "python",
   "name": "gvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
